% How is the company evolving, on a weekly basis.

February/March
==============

Get data warehouse in place. Clean small business data.

March/April
===========
Grow. Implement scripts to help you grow more efficiently.

July
====
*Problem:* Passwords were weak and being shared in plaintext in public channels. Solution was to implement LastPass

*Problem:* Our organization name presented trademark issues. Solution: change name.

August
======

Early August
-------------
Moving into a more permanent office space.
Getting internet set up.
*Issue:* Negotiating the cost of setting up a network.

Late August
----------------------------
Hiring an office manager / Director of 
Talent Acquisition


September
=========

*Problem:* There is too much, in too many different topics, that I am trying to maintain work on. 
 - Developing and implementing analytics tracking in the organization. 
 - Ingestion (ETL, cleaning, translation, even finding sources) of product data. Data architecture issues, including streamlining our database tables, merging our CRM (and possible reconfiguration), warehousing more effectively. Much of that likely falls under Engineering.
 - Finding solid claims data and making use of it. Considering other machine learning applications. Dynamic Knowledgebase. Bots. 
   - Some of these require more user data, more users, higher engagement. Probably. More product.

Hiring Director of Engineering - able to manage code base, do code reviews, build out robust code

Sept 18
-------
*Problem:* I'm having trouble assessing my priorities (or the priorities of the organization) and focusing on just one thing. An organizational solution would be to have a technical project manager or other higher level individual to determine the direction of my projects.
*Problem:* Accountability

Building out a data science and analytics team.

Hiring analysts / ML engineers.

October
=======

October 2
---------
Struggling with making time for data science / ML projects. Brainstormed with Soren to formulate possible projects. Need to reserve calendar time for these things. 
Feeling stretched across a number of unrelated tasks, from data ingestion to analytics and reporting to ML ideation. 


New Director of Product Joined

October 9
---------
New Director of Product got started. He's helping to think about UX/UI, Customer Experience, Length of flows, and the metrics we will need.

One thing that really needs to be done is to solidify our tracking capabilities. This means more carefully defining things like 'engagement', 'concierge request', etc. And having the capabilities to actually be tracking these things. Are all the events in place? Can we segment effectively? How do we go from our current setup to a better one? People need to start looking at dashboards, then we have meetings to solidify definitions and implement tracking.

In my approach to implementing analytics, I shouldn't have started with just piecing things together in a dashboard. Instead, I should have met with various people do identify and really define the KPIs we were interested in. Document these definitions, build the tools to track them, get them in front of the people who need them. 

October 16
----------
Director of Product sends slides defining our new Beacon of Truth push. Also sends out brainstorming document for the key engagement metrics we'll use, both choosing and defining. Once we get this he'll start to send these out on a regular basis.

More ticketing. One problem about last few months (since I got here) has been constantly moving targets. Never adequately dealing with challenges, measuring results, following up on results. Just moving on to the next thing and the previous thing stagnates.

Product helps with ticket creation. Not sure how engagement is even being driven. Problems with how it's being tracked.

October 23
----------
I need to start giving the data science group more direction. I started out embedded in the engineering team, which means I've picked up engineering related projects and taken on engineering related responsibilities. A large part of this was necessary, considering that there was hardly any data on which to do data science. We had no "users", only people coming in through the survey. And it was very difficult to track what was happening to these people. The warehouse was put in place back in February/March in order to store the Salesforce, web analytics, and Zendesk data. Many of the projects were rolled out with no analytics plan in place beforehand. Only retroactively did we think about what we wanted to measure and try to get in place the tools we needed. 

How will the data science group function moving forward? What types of problems will it solve? What types of problems will it encounter?

First of all, data science needs to separate from engineering. I need to stop attending the daily standups and other engineering meetings. But how will the day-to-day or week-to-week of the data science team move along? We need to have meetings to touch base. There will be analytics needs of the company that need to be addressed. How do we filter and prioritize these needs? How do we maintain focus on larger scale problems? A manager normally helps with the filtering and prioritization process, as well as tracking progress. 

One of the things we need to be doing better is in how we track and push forward engagement with out product. Also providing some analysis of the health plan data itself, perhaps tied into a blog post about it, or brainstorming metrics that could be included in the plan recommendation. Acquiring claims data. Implementing automated tagging (and actions) for incoming Zendesk tickets.

Challenges: scoping problems, prioritizing problems, tracking progress, handling organizational analytics needs while maintaining focus on important problems.

Morning status meeting: sharing progress and problems. Working through problems throughout the day. Meeting with people when necessary.

For product, or anything company wide, an analytics plan should be formulated (identifying key metrics, how to track them, building a dashboard) before hand. We need dashboards in place around the major company metrics. We need to make sure that the KPIs we're watching are the important ones.

Look into getting an internal blog (probably through Atlassian) up and running.

October 30
----------
What am I struggling with? What is the company struggling with?

I'm struggling to do my job. To understand what my job should be and to do it. No one is here to tell me what my job should be. I should pull together metrics and reports. Or should I be doing research on machine learning applications. But I keep getting caught up. 


November 13
-----------
Neal (CTO) resigns, with reference made to work-life balance issues. Another engineer is let go because of sexist remarks. 

Team has been struggling with the open enrollment project, figuring out health insurance / technical requirements on the fly, often responding to QA finding that prices differ between our site and healthcare.gov, or when users point out issues. Everyone has been working long hours and appears constantly frustrated when things are not perfect.

November 27
-----------
The data science team has absorbed some of the data engeering contractors, but the team breakdown was determined by Christine. Soren will likely be taking steps to readjust.

I have had conversations with Product people and CX about what might be the best application of our time and talents, but Christine has other ideas. She wants to build this dynamic knowledgebase, which Soren and I have been working to define in terms of actionable projects. I suggested that the first part of the project would be to pull together metrics on the functioning/efficiency of our current systems, but Christine said that the metrics/analysis work falls to the other group (Ethan/Yanny/Belinda) and we should not spend time on that since it won't change that this project is happening. 

My essential take is that conversations with product and CX would push us to develop better analytics and to actually attack the question of what data science would provide the most value to the company. Christine has decided that ML and intelligent concierge systems should be priority.

Our recruiter announced he was leaving earlier this week. DevOps was let go.

December 4
----------
I'm struggling this week. This is a lack of direction. I should form a direction myself, for the team, by talking to people throughout the organization and seeing what they need from a data science perspective. But I can't just do that, because I need buy in from Christine and she and I have different ideas about what the data team should do. The current project doesn't have enough scope. 

The big problem is that Christine wants and strongly believes the data science team should be doing ML and building ML products. My belief is that there is much more to gain by improving our engineering, design, marketing, and analytics reporting. But Christine does not want to hear that we should scrap our ML efforts. In some sense, that is the company's brand, even though we do none of that. 

-

Perhaps one problem is that I am very much aware of the value that data and observation can bring to the work that we do, while others are more familiar with operating and evaluating post-hoc. I am frustrated when I am left out of conversations I think I, or the data/analytics team more broadly, should have participated in. But instead of being frustrated I should aim to inform. Explain the benefits of involving analytics into projects. But maybe these teams already have reporting capabilities. They have formulated funnels and know how to read them to assess a change. In which case, what is the point of a data science team?

That is one thing I am struggling to learn. I have some of the technical skills. But I am unsure of how to be effective, or how to get an organization to use a data science team effectively.

Many of the problems we face are the same variety as those faced last year. One year is enough time to solve these problems, but only if they are the ones you focus on. The focus has not been there. It has been on increasing survey takers, building underutilized product features haphazardly.

And of course, all I've done is complain instead of fixing things. Not quite true, but it sometimes feels like that. 
